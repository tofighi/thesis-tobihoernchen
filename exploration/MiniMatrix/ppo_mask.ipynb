{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import time\n",
                "import json\n",
                "from alpyne.client.alpyne_client import AlpyneClient\n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.utils import set_random_seed\n",
                "from stable_baselines3.common.env_util import make_vec_env\n",
                "\n",
                "sys.path.append(\"../..\")\n",
                "from thesis.envs.matrix_routing_centralized import MatrixRoutingCentral\n",
                "from thesis.policies.routing_attention import RoutingFE\n",
                "from thesis.policies.ppo_ac_attention import AttentionACPolicy\n",
                "\n",
                "seed = 42\n",
                "set_random_seed(seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "models_dir = \"../../models/MiniMatrix_Routing_Attn\"\n",
                "logdir = \"../../logs/MiniMatrix_Routing_Attn\"\n",
                "fleetsize = 6\n",
                "max_fleetsize = 10\n",
                "run_name = f\"PPO-{fleetsize}-{max_fleetsize}-{time.strftime('%d_%m-%H_%M_%S')}-{seed}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "env_args = dict(\n",
                "        reward_target = 1, \n",
                "        reward_distance = 0.05,\n",
                "        reward_block = -0.5, \n",
                "        dispatchinginterval=30,\n",
                "        routinginterval = 2,\n",
                "        withCollisions = True,\n",
                "        blockTimeout = 5,\n",
                "        routingOnNode = False,\n",
                "        # coordinates = False,\n",
                "        includeNodesInReach = True,\n",
                "    )\n",
                "\n",
                "ppo_args = dict(\n",
                "    #learning_rate = 3e-3,\n",
                "    n_steps = 64,\n",
                "    batch_size = 512,\n",
                "    #ent_coef = 0.2,\n",
                "    target_kl = 0.003,\n",
                "    gamma = 0.7,\n",
                "    clip_range = 0.3\n",
                ")\n",
                "fe_args = dict(\n",
                "    max_fleetsize=max_fleetsize,\n",
                "    embed_dim = 64,\n",
                "    n_heads = 8,\n",
                "    depth = 8\n",
                ")\n",
                "net_arch = [dict(pi = [], vf = [])]\n",
                "\n",
                "hparams = dict(\n",
                "    fleetsize = fleetsize,\n",
                "    max_fleetsize = max_fleetsize,\n",
                "    env_args = env_args,\n",
                "    ppo_args = ppo_args,\n",
                "    fe_args = fe_args,\n",
                "    net_arch = net_arch\n",
                ")\n",
                "with open(f\"{models_dir}/{run_name}.json\", 'w') as outfile:\n",
                "    json.dump(hparams, outfile, indent = 3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_66681_l4gi268c)\n",
                        "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n"
                    ]
                }
            ],
            "source": [
                "i = [0]\n",
                "\n",
                "client = AlpyneClient(\"../../envs/MiniMatrix.zip\", port=51150)\n",
                "\n",
                "env = make_vec_env(MatrixRoutingCentral, 8, env_kwargs=dict(\n",
                "    max_seconds = 5*60, \n",
                "    fleetsize = fleetsize, \n",
                "    max_fleetsize=max_fleetsize, \n",
                "    config_args = env_args,\n",
                "    counter = i,\n",
                "    client = client\n",
                "))\n",
                "\n",
                "model =PPO(\n",
                "    AttentionACPolicy,\n",
                "    env, \n",
                "    tensorboard_log= logdir,\n",
                "    device = \"cuda\",\n",
                "    policy_kwargs=dict(\n",
                "        net_arch = net_arch,\n",
                "        features_extractor_class=RoutingFE, \n",
                "        features_extractor_kwargs=fe_args\n",
                "        ),\n",
                "    **ppo_args,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "TIMESTEPS = 50000\n",
                "for i in range(1, 15):\n",
                "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=run_name)#,callback=MiniMatrixCallback())\n",
                "    model.save(f\"{models_dir}/{run_name}-{TIMESTEPS * i}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor(3.)"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch\n",
                "torch.Tensor([1,2,3]).max(dim=0)[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[0.],\n",
                            "        [0.],\n",
                            "        [0.],\n",
                            "        [1.],\n",
                            "        [0.],\n",
                            "        [0.],\n",
                            "        [0.],\n",
                            "        [0.],\n",
                            "        [0.],\n",
                            "        [0.]])"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.policy.features_extractor.mask[3]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([16, 15])"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "torch.rand(8,10,15)[torch.rand(8,10)<0.2].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[4.6802e-01, 4.1489e-01, 1.1272e-01, 9.0595e-01, 5.7178e-01, 9.3568e-01,\n",
                            "         9.8407e-01, 2.0722e-01, 5.0167e-01, 9.6639e-02, 9.8368e-02, 9.3464e-01,\n",
                            "         6.1793e-01, 7.2499e-02, 2.1527e-01],\n",
                            "        [1.6276e-01, 2.5012e-01, 4.0997e-01, 5.0386e-01, 6.8810e-01, 6.3436e-01,\n",
                            "         5.5789e-01, 7.5241e-01, 7.3755e-01, 8.2399e-01, 1.3555e-02, 8.8460e-02,\n",
                            "         5.8754e-01, 8.7182e-02, 4.0445e-01],\n",
                            "        [6.1244e-01, 3.5204e-02, 2.7557e-01, 1.6139e-01, 2.2698e-01, 4.8263e-01,\n",
                            "         6.5265e-01, 8.8682e-01, 4.5719e-01, 3.3674e-01, 5.2818e-01, 4.6900e-01,\n",
                            "         4.9338e-01, 3.8698e-01, 5.6798e-01],\n",
                            "        [3.1807e-01, 9.3433e-01, 6.1566e-01, 6.4365e-01, 8.3279e-02, 7.8307e-01,\n",
                            "         8.2076e-01, 7.2095e-01, 6.6044e-02, 7.9812e-01, 6.4318e-01, 1.6442e-01,\n",
                            "         3.1523e-01, 7.0239e-01, 3.7467e-01],\n",
                            "        [6.3371e-02, 5.1225e-01, 6.8430e-01, 2.0919e-01, 2.1251e-01, 7.9288e-01,\n",
                            "         5.9515e-01, 1.0767e-01, 3.7688e-01, 3.8917e-01, 8.6497e-01, 2.4291e-01,\n",
                            "         7.1752e-01, 2.8744e-02, 9.9713e-01],\n",
                            "        [6.4916e-01, 9.2886e-01, 7.7461e-02, 7.9096e-01, 2.1667e-01, 8.2861e-01,\n",
                            "         1.6306e-01, 3.9669e-01, 2.0459e-01, 4.8119e-01, 9.0883e-01, 1.3830e-01,\n",
                            "         2.6122e-01, 4.7298e-02, 5.3882e-01],\n",
                            "        [8.3058e-01, 3.4909e-01, 7.4622e-02, 5.6129e-01, 4.9138e-01, 7.0331e-01,\n",
                            "         2.6606e-01, 5.1757e-01, 1.6152e-01, 6.6878e-01, 1.4412e-01, 1.0957e-01,\n",
                            "         6.0091e-01, 5.8488e-01, 3.5274e-01],\n",
                            "        [2.9687e-01, 3.6195e-01, 6.9643e-01, 1.5863e-01, 1.2345e-02, 8.7791e-01,\n",
                            "         3.5608e-01, 3.2307e-01, 2.7693e-02, 7.1584e-01, 9.4300e-01, 6.7374e-01,\n",
                            "         7.0221e-01, 9.4777e-01, 5.5703e-02],\n",
                            "        [7.9716e-01, 4.6042e-01, 4.6057e-01, 1.0989e-01, 7.1412e-01, 8.3497e-01,\n",
                            "         8.3428e-01, 2.4151e-01, 6.5590e-01, 9.3923e-01, 5.0643e-01, 5.3827e-01,\n",
                            "         8.8599e-01, 5.8495e-01, 5.4331e-01],\n",
                            "        [4.9292e-01, 9.3901e-01, 4.6611e-01, 1.7515e-01, 4.2596e-01, 8.7946e-01,\n",
                            "         4.0604e-01, 9.1163e-01, 6.3100e-01, 2.6476e-01, 2.7184e-01, 3.3680e-01,\n",
                            "         3.4352e-01, 4.0378e-01, 1.2305e-01],\n",
                            "        [9.6687e-01, 3.3935e-01, 8.8500e-02, 8.6880e-01, 5.5005e-01, 3.4816e-01,\n",
                            "         5.3080e-01, 4.8769e-01, 2.2020e-01, 6.7498e-01, 4.8809e-01, 5.8415e-01,\n",
                            "         6.4597e-01, 8.3171e-01, 6.0706e-01],\n",
                            "        [3.0770e-01, 8.3225e-01, 8.5669e-01, 6.0729e-01, 4.1919e-01, 4.6496e-01,\n",
                            "         5.7717e-01, 7.3914e-01, 5.1667e-01, 1.5094e-01, 8.6044e-01, 3.2011e-01,\n",
                            "         9.9746e-01, 1.5678e-01, 5.3558e-01],\n",
                            "        [9.6829e-01, 9.8400e-01, 8.6563e-01, 2.3455e-01, 6.6573e-01, 3.8961e-01,\n",
                            "         9.8575e-01, 5.9403e-01, 1.3309e-02, 1.7371e-01, 8.4315e-01, 1.3956e-01,\n",
                            "         8.1400e-01, 3.9418e-03, 9.7170e-01],\n",
                            "        [6.9508e-02, 4.7509e-01, 3.6305e-01, 8.9137e-01, 9.4411e-02, 3.9948e-01,\n",
                            "         9.8076e-01, 8.5344e-01, 7.4157e-01, 5.9672e-01, 1.2156e-01, 2.1384e-01,\n",
                            "         7.9226e-01, 9.3754e-01, 4.9733e-02],\n",
                            "        [7.4850e-01, 1.7834e-01, 1.5283e-01, 8.1206e-02, 7.0791e-01, 7.2977e-01,\n",
                            "         9.1731e-01, 2.0250e-01, 1.8434e-01, 5.7040e-01, 6.9287e-02, 3.3759e-01,\n",
                            "         4.1388e-01, 3.1819e-01, 1.8215e-01],\n",
                            "        [4.4632e-01, 6.9123e-01, 2.2635e-01, 1.9537e-01, 6.1887e-01, 5.8985e-01,\n",
                            "         7.1178e-01, 6.1664e-01, 6.8801e-01, 2.8087e-01, 9.9009e-01, 6.0312e-01,\n",
                            "         8.0682e-01, 2.7298e-01, 2.8369e-01],\n",
                            "        [9.8634e-01, 2.1587e-01, 4.8006e-01, 2.4381e-01, 1.0118e-01, 4.2588e-01,\n",
                            "         8.9793e-01, 9.8146e-01, 5.7435e-01, 7.4326e-01, 4.4499e-01, 2.1716e-01,\n",
                            "         2.5422e-01, 3.8790e-02, 1.1945e-01],\n",
                            "        [9.1435e-01, 7.9501e-02, 6.6440e-01, 1.3406e-01, 8.9332e-01, 7.2149e-01,\n",
                            "         4.4521e-01, 5.0941e-01, 5.6240e-02, 6.4674e-01, 6.0281e-01, 4.3231e-01,\n",
                            "         4.2076e-01, 8.5108e-01, 2.3858e-02],\n",
                            "        [5.5723e-01, 1.5022e-01, 8.0341e-01, 5.5858e-01, 7.7209e-01, 9.3845e-01,\n",
                            "         3.1012e-01, 3.4137e-01, 5.8121e-01, 7.2855e-01, 4.0770e-01, 3.9863e-01,\n",
                            "         6.7185e-03, 6.4047e-01, 7.4042e-01],\n",
                            "        [1.8579e-01, 6.0669e-01, 9.0550e-01, 7.4318e-02, 4.0193e-01, 1.3787e-02,\n",
                            "         7.9254e-01, 7.9915e-01, 9.8035e-01, 9.5605e-01, 8.5687e-01, 7.4630e-01,\n",
                            "         1.1555e-01, 1.8653e-01, 9.7127e-01],\n",
                            "        [1.7989e-01, 3.6290e-01, 9.8119e-02, 2.9251e-01, 6.8166e-01, 5.5799e-01,\n",
                            "         3.9656e-01, 9.1933e-01, 9.5592e-01, 6.3052e-01, 6.8877e-01, 1.4009e-01,\n",
                            "         9.5060e-01, 7.4092e-01, 1.9168e-01],\n",
                            "        [3.4205e-01, 5.7543e-02, 5.2323e-03, 5.7273e-01, 2.4203e-01, 8.5347e-01,\n",
                            "         9.7777e-01, 6.6989e-01, 9.3130e-01, 9.7580e-01, 6.5422e-02, 6.3503e-01,\n",
                            "         1.6828e-01, 2.7589e-02, 9.3124e-01],\n",
                            "        [7.3523e-01, 5.4957e-01, 8.9656e-01, 3.0260e-01, 1.7147e-01, 7.5985e-01,\n",
                            "         8.5380e-01, 5.2191e-01, 7.2655e-01, 4.8023e-01, 9.6706e-01, 4.2848e-01,\n",
                            "         7.3041e-02, 5.8491e-01, 1.7157e-01],\n",
                            "        [4.9640e-01, 3.4413e-01, 8.4716e-01, 3.2734e-01, 5.1255e-01, 8.2428e-02,\n",
                            "         4.2526e-01, 2.9880e-02, 7.6699e-01, 3.3879e-01, 6.2047e-01, 9.1287e-01,\n",
                            "         1.1389e-01, 7.4540e-01, 5.5750e-01],\n",
                            "        [1.8716e-01, 2.4388e-01, 8.4902e-01, 7.3289e-01, 5.0074e-01, 4.1765e-01,\n",
                            "         7.3043e-02, 1.3893e-01, 3.4040e-01, 4.0092e-01, 7.9028e-02, 2.7262e-02,\n",
                            "         3.2742e-01, 7.9431e-01, 5.0820e-01],\n",
                            "        [1.0568e-01, 6.8191e-01, 8.5272e-01, 1.3396e-01, 2.6218e-01, 3.1834e-02,\n",
                            "         9.5701e-01, 1.3887e-01, 1.9688e-01, 4.1282e-01, 3.3741e-01, 5.6638e-01,\n",
                            "         2.8022e-02, 9.5264e-01, 2.0409e-01],\n",
                            "        [2.7319e-01, 8.4920e-01, 3.9122e-01, 9.9677e-01, 4.4315e-02, 5.9735e-01,\n",
                            "         1.8766e-01, 5.5172e-01, 9.4936e-01, 6.6847e-01, 3.8652e-01, 7.0555e-01,\n",
                            "         1.7554e-01, 8.3585e-03, 4.8017e-01],\n",
                            "        [8.5042e-01, 3.5480e-01, 2.1759e-01, 4.6027e-01, 5.2334e-01, 7.9748e-01,\n",
                            "         8.4266e-01, 7.2173e-01, 9.1859e-02, 9.7494e-01, 8.5204e-01, 5.0665e-01,\n",
                            "         5.3227e-01, 5.9444e-01, 1.9091e-01],\n",
                            "        [5.4558e-02, 2.0004e-01, 3.2598e-01, 4.6219e-01, 9.9494e-01, 9.2922e-01,\n",
                            "         1.6923e-01, 2.1455e-01, 6.3386e-01, 6.9086e-01, 2.2240e-01, 2.6758e-01,\n",
                            "         6.9011e-01, 2.9473e-01, 6.7919e-01],\n",
                            "        [5.8440e-02, 8.9108e-01, 8.5295e-01, 6.8531e-01, 7.5540e-01, 4.2716e-01,\n",
                            "         1.1453e-01, 4.7048e-01, 5.3587e-01, 9.9795e-01, 2.1738e-01, 3.0478e-01,\n",
                            "         6.9708e-02, 9.2263e-02, 6.3013e-01],\n",
                            "        [1.9236e-01, 8.3776e-01, 7.8162e-01, 7.7681e-01, 9.1461e-01, 7.6800e-01,\n",
                            "         7.6044e-01, 5.5097e-01, 2.9268e-01, 2.6462e-01, 3.7737e-01, 4.4245e-01,\n",
                            "         1.4357e-01, 5.4767e-01, 4.5943e-01],\n",
                            "        [2.0854e-02, 1.2627e-01, 9.9865e-01, 2.2396e-02, 1.5976e-01, 3.3037e-01,\n",
                            "         1.4492e-01, 1.1162e-01, 1.4210e-01, 3.4342e-01, 9.0118e-01, 1.7138e-01,\n",
                            "         4.5966e-01, 3.3080e-01, 4.9128e-01],\n",
                            "        [4.1729e-01, 9.4237e-01, 9.3116e-01, 8.8260e-01, 4.4421e-01, 9.6413e-01,\n",
                            "         4.2400e-02, 4.2803e-01, 3.6944e-01, 8.5420e-02, 2.2491e-01, 9.5717e-01,\n",
                            "         1.7325e-01, 1.8532e-01, 5.8643e-01],\n",
                            "        [2.2260e-02, 9.1894e-01, 1.5731e-01, 7.3965e-01, 7.0993e-01, 4.1451e-01,\n",
                            "         6.0515e-01, 7.2511e-01, 5.3301e-01, 3.3814e-01, 3.5759e-01, 3.6876e-01,\n",
                            "         4.7181e-01, 8.7758e-02, 3.6658e-01],\n",
                            "        [6.7763e-01, 3.8833e-01, 1.0511e-01, 1.8150e-01, 4.1869e-01, 8.0663e-01,\n",
                            "         4.9662e-01, 9.5008e-01, 4.3724e-01, 2.2053e-01, 7.8379e-01, 5.2946e-01,\n",
                            "         8.7294e-01, 9.7271e-01, 8.2526e-01],\n",
                            "        [7.1147e-01, 5.8713e-01, 6.2233e-01, 1.4196e-01, 3.7075e-01, 3.4487e-01,\n",
                            "         1.3692e-01, 5.3076e-01, 4.8295e-01, 3.6569e-01, 2.3365e-01, 8.2500e-01,\n",
                            "         8.4499e-01, 7.6304e-01, 1.6654e-01],\n",
                            "        [3.5683e-01, 2.5068e-01, 8.7676e-01, 4.0908e-01, 8.8288e-01, 7.6313e-01,\n",
                            "         6.9884e-01, 4.5742e-01, 5.5887e-01, 3.1880e-01, 7.0388e-01, 3.1313e-01,\n",
                            "         3.1774e-01, 4.4252e-01, 8.7093e-01],\n",
                            "        [4.3412e-01, 1.7390e-01, 9.4298e-01, 1.2770e-01, 3.7322e-01, 1.1181e-01,\n",
                            "         8.9727e-01, 1.5778e-03, 4.3853e-01, 2.2586e-01, 7.7315e-01, 6.9448e-01,\n",
                            "         1.4318e-01, 2.3492e-01, 1.4491e-01],\n",
                            "        [8.5762e-01, 8.1505e-01, 3.8733e-01, 7.3298e-01, 8.5768e-01, 5.2405e-01,\n",
                            "         4.9800e-01, 3.6208e-01, 5.2373e-01, 8.1011e-01, 7.5569e-01, 9.3399e-01,\n",
                            "         6.8318e-01, 5.6813e-01, 1.9854e-01],\n",
                            "        [9.7971e-01, 6.6231e-01, 9.4651e-01, 4.8962e-01, 4.4436e-01, 1.2491e-01,\n",
                            "         3.6132e-03, 3.1443e-01, 4.4104e-01, 2.2982e-02, 5.1782e-01, 8.8172e-01,\n",
                            "         7.4350e-01, 7.8030e-01, 9.2218e-02],\n",
                            "        [9.9049e-01, 4.9708e-01, 3.9059e-04, 8.0859e-01, 1.9386e-01, 2.3211e-01,\n",
                            "         2.8413e-01, 1.8147e-01, 7.6378e-02, 3.0946e-01, 3.7161e-01, 1.7955e-01,\n",
                            "         2.4379e-01, 5.8533e-01, 3.6978e-01],\n",
                            "        [3.3796e-01, 5.2751e-01, 5.6576e-01, 1.9697e-01, 9.4568e-01, 7.8787e-01,\n",
                            "         6.4004e-01, 8.7034e-01, 3.0785e-01, 9.4288e-01, 3.4918e-01, 9.7805e-02,\n",
                            "         4.8207e-01, 4.7260e-01, 7.4301e-01]])"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch \n",
                "reshaped = torch.rand(8,10,15)\n",
                "reshaped[model.policy.features_extractor.mask.squeeze().detach() == 1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in range(15, 30):\n",
                "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=run_name)#,callback=MiniMatrixCallback())\n",
                "    model.save(f\"{models_dir}/{run_name}-{TIMESTEPS * i}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 ('thesis')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "dc7f4105f9f5e395f215a7643dd52717d50b308583dcde27027fbaaaba0d8cea"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
